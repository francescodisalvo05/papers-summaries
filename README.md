# Papers summaries

Inspired by Adrian Colyer (known for [the morning paper](https://blog.acolyer.org/)) and Vitaly Kurin (known as [YobiByte](https://yobibyte.github.io/)), I decided to share summaries of the papers I read for my research and for fun.

I usually *try* to stay up-to-date through the latest conferences, as well as with notifications from Google Scholar and ArXiv. Recently, I also started using and fine-tuning [scholar-inbox](https://www.scholar-inbox.com/), a paper recommender system developed at the University of TÃ¼bingen [[news](https://tuebingen.ai/news/stay-ahead-in-research-with-scholar-inbox)].

## 2024

`10` Wilson, Samuel, et al. "Hyperdimensional feature fusion for out-of-distribution detection." Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2023. [[summary](summaries/10_wilson2023hyperdimensional.md)], [[source](https://openaccess.thecvf.com/content/WACV2023/papers/Wilson_Hyperdimensional_Feature_Fusion_for_Out-of-Distribution_Detection_WACV_2023_paper.pdf
)]

`09` Fu, Stephanie, et al. "FeatUp: A Model-Agnostic Framework for Features at Any Resolution." (ICLR 2024). [[summary](summaries/09_fu2024featup.md)], [[source](https://arxiv.org/abs/2403.10516)]

`08` Balestriero, Randall, Jerome Pesenti, and Yann LeCun. "Learning in high dimension always amounts to extrapolation." (arXiv 2021). [[summary](summaries/08_balestriero2021learning.md)], [[source](https://arxiv.org/abs/2110.09485)]

`07` Crisostomi, Donato, et al. "From Charts to Atlas: Merging Latent Spaces into One." (PMLR 2023) [[summary](summaries/07_crisostomi2023from.md)], [[source](https://arxiv.org/abs/2311.06547)]

`06` Cannistraci, Irene, et al. "From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication." (ICLR 2024). [[summary](summaries/06_cannistraci2023from.md)], [[source](https://arxiv.org/abs/2310.01211)]

`05` Moschella, Luca, et al. "Relative Representations Enable Zero-Shot Latent Space Communication". (ICLR 2023). [[summary](summaries/05_moschella2023relative.md)], [[source](https://arxiv.org/abs/2209.15430)]

`04` Liu, Jiahui, et al. "Few-shot Learning for Inference in Medical Imaging with Subspace Feature Representations." (arXiv 2023). [[summary](summaries/04_liu2023few.md)], [[source](https://arxiv.org/pdf/2306.11152.pdf)]

`03` Stoica, George, et al. "ZipIt! Merging Models from Different Tasks without Training." (arXiv 2023). [[summary](summaries/03_stoica2023zipit.md)], [[source](https://openreview.net/forum?id=LEYUkvdUhq)]

`02` Wortsman, Mitchell, et al. "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time." (ICML 2022). [[summary](summaries/02_wortsman2022model.md)], [[source](https://arxiv.org/pdf/2203.05482.pdf)]

`01` Yang, Yuncheng, et al. "Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation." (MICCAI 2023). [[summary](summaries/01_yang2023pick.md)], [[source](https://arxiv.org/pdf/2307.11958.pdf)]